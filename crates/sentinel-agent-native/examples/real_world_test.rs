//! REAL-WORLD TEST: Full SENTINEL SWARM Execution
//!
//! âš ï¸  This test makes ACTUAL API calls to LLM providers!
//! Set your OPENROUTER_API_KEY before running.

use sentinel_agent_native::providers::router::ProviderRouter;
use sentinel_agent_native::swarm::{llm::SwarmLLMClient, SwarmConfig, SwarmCoordinator};
use std::sync::Arc;
use std::time::{Duration, Instant};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸš€ SENTINEL SWARM - REAL WORLD TEST\n");
    println!("âš ï¸  This will make ACTUAL API calls to LLM providers\n");

    // Check for API key
    let api_key = std::env::var("OPENROUTER_API_KEY")
        .or_else(|_| std::env::var("OPENAI_API_KEY"))
        .or_else(|_| std::env::var("ANTHROPIC_API_KEY"));

    if api_key.is_err() {
        println!("âŒ No API key found!");
        println!("\nPlease set one of these environment variables:");
        println!("  - OPENROUTER_API_KEY");
        println!("  - OPENAI_API_KEY");
        println!("  - ANTHROPIC_API_KEY");
        println!("\nGet a free key at: https://openrouter.ai/keys");
        return Ok(());
    }

    println!("âœ“ API key found\n");

    // Initialize ProviderRouter (auto-detects from env)
    println!("ğŸ“¡ Initializing ProviderRouter...");
    let router = match ProviderRouter::from_env() {
        Ok(r) => {
            println!("  âœ“ ProviderRouter configured");
            Arc::new(r)
        }
        Err(ref e) => {
            println!("  âŒ Failed to configure: {}", e);
            return Ok(());
        }
    };

    // Create LLM client with circuit breaker
    let llm_client = Arc::new(SwarmLLMClient::new(router).with_concurrency(3));

    // Configure swarm with safety limits
    let config = SwarmConfig {
        quorum_threshold: 0.75,
        consensus_interval_ms: 100,
        max_concurrent_llm: 3,
        enable_prediction: true,
        enable_balancing: true,
        vote_timeout_ms: 5000,
        max_agents: 5,                // Safety limit
        max_execution_time_secs: 120, // 2 minute timeout
        max_memory_mb: 256,
        enable_circuit_breaker: true,
        llm_retry_count: 2,
    };

    // Test 1: Simple task
    println!("\nğŸ¯ TEST 1: Simple task (single agent)");
    println!("Goal: Create a function to validate email addresses\n");

    let goal1 = "Create a Rust function to validate email addresses using regex";

    let swarm1 = SwarmCoordinator::from_goal(goal1, llm_client.clone(), config.clone()).await?;

    println!("  Spawning agents...");
    let start = Instant::now();
    let result1 = swarm1.run().await;
    let elapsed1 = start.elapsed();

    match result1 {
        Ok(ref result) => {
            println!("  âœ“ Execution completed in {:?}", elapsed1);
            println!("  âœ“ Agents: {}", result.agent_count);
            println!(
                "  âœ“ Files extracted: {}",
                result
                    .outputs
                    .iter()
                    .map(|o| o.files_written.len())
                    .sum::<usize>()
            );

            // Show extracted files
            for output in &result.outputs {
                for file in &output.files_written {
                    println!("    ğŸ“„ {}", file);
                }
            }
        }
        Err(ref e) => {
            println!("  âŒ Execution failed: {}", e);
        }
    }

    // Test 2: Complex task (multiple agents)
    println!("\nğŸ¯ TEST 2: Complex task (multiple agents)");
    println!("Goal: Build authentication module with JWT, password hashing, and tests\n");

    let goal2 = "Build a complete JWT authentication module in Rust with: token generation, password hashing with bcrypt, token validation, and comprehensive unit tests";

    let swarm2 = SwarmCoordinator::from_goal(goal2, llm_client.clone(), config.clone()).await?;

    println!("  Spawning agents...");
    let start = Instant::now();
    let result2 = swarm2.run().await;
    let elapsed2 = start.elapsed();

    match result2 {
        Ok(ref result) => {
            println!("  âœ“ Execution completed in {:?}", elapsed2);
            println!("  âœ“ Agents: {}", result.agent_count);
            println!("  âœ“ Outputs: {}", result.outputs.len());
            println!("  âœ“ Conflicts detected: {}", result.conflicts_detected);
            println!("  âœ“ Conflicts resolved: {}", result.conflicts_resolved);
            println!("  âœ“ Consensus rounds: {}", result.consensus_rounds);

            // Show extracted files
            let total_files: usize = result.outputs.iter().map(|o| o.files_written.len()).sum();
            println!("  âœ“ Total files extracted: {}", total_files);

            for output in &result.outputs {
                for file in &output.files_written {
                    println!("    ğŸ“„ {} (agent: {:?})", file, output.agent_type);
                }
            }

            // Show content preview
            println!("\n  ğŸ“„ Content preview:");
            for output in &result.outputs {
                if !output.content.is_empty() {
                    let preview: String = output.content.chars().take(200).collect();
                    println!("\n  --- {:?} ---", output.agent_type);
                    println!("  {}", preview);
                    if output.content.len() > 200 {
                        println!("  ... ({} more chars)", output.content.len() - 200);
                    }
                    break; // Show only first agent's content
                }
            }
        }
        Err(ref e) => {
            println!("  âŒ Execution failed: {}", e);
        }
    }

    // Test 3: Circuit breaker test
    println!("\nğŸ¯ TEST 3: Circuit Breaker & Error Handling");

    let stats = llm_client.get_stats().await;
    println!("  LLM Stats:");
    println!("    - Total requests: {}", stats.total_requests);
    println!("    - Successful: {}", stats.successful_requests);
    println!("    - Failed: {}", stats.failed_requests);
    println!("    - Retries: {}", stats.retry_count);
    println!(
        "    - Avg response time: {:.0}ms",
        stats.avg_response_time_ms
    );

    // Summary
    println!("\n{}", "=".repeat(60));
    println!("ğŸ“Š TEST SUMMARY");
    println!("{}", "=".repeat(60));

    if result1.is_ok() && result2.is_ok() {
        println!("\nâœ… ALL TESTS PASSED!");
        println!("\nSENTINEL SWARM is working correctly with:");
        println!("  âœ“ Multi-provider LLM support");
        println!("  âœ“ Automatic file extraction from responses");
        println!("  âœ“ Circuit breaker pattern");
        println!("  âœ“ Timeout and limit enforcement");
        println!("  âœ“ Multi-agent parallel execution");
        println!("  âœ“ Conflict detection and resolution");
    } else {
        println!("\nâš ï¸  SOME TESTS FAILED");
        println!("Check error messages above.");
    }

    println!("\nğŸ’° Cost Estimate:");
    let total_tokens = stats.total_tokens;
    let estimated_cost = (total_tokens as f64 / 1000.0) * 0.002; // $0.002 per 1K tokens (approximate)
    println!("  ~{} tokens used", total_tokens);
    println!("  ~${:.4} estimated cost", estimated_cost);

    Ok(())
}

/*
Expected output with working API key:

ğŸš€ SENTINEL SWARM - REAL WORLD TEST

âš ï¸  This will make ACTUAL API calls to LLM providers

âœ“ API key found

ğŸ“¡ Initializing ProviderRouter...
  âœ“ ProviderRouter configured

ğŸ¯ TEST 1: Simple task (single agent)
Goal: Create a function to validate email addresses

  Spawning agents...
  âœ“ Execution completed in 3.2s
  âœ“ Agents: 1
  âœ“ Files extracted: 1
    ğŸ“„ src/email_validator.rs

ğŸ¯ TEST 2: Complex task (multiple agents)
Goal: Build authentication module with JWT...

  Spawning agents...
  âœ“ Execution completed in 15.8s
  âœ“ Agents: 4
  âœ“ Outputs: 4
  âœ“ Conflicts detected: 1
  âœ“ Conflicts resolved: 1
  âœ“ Consensus rounds: 42
  âœ“ Total files extracted: 3
    ğŸ“„ src/auth/mod.rs (agent: AuthArchitect)
    ğŸ“„ src/auth/jwt.rs (agent: JWTCoder)
    ğŸ“„ tests/auth_tests.rs (agent: TestWriter)

============================================================
ğŸ“Š TEST SUMMARY
============================================================

âœ… ALL TESTS PASSED!

SENTINEL SWARM is working correctly with:
  âœ“ Multi-provider LLM support
  âœ“ Automatic file extraction from responses
  âœ“ Circuit breaker pattern
  âœ“ Timeout and limit enforcement
  âœ“ Multi-agent parallel execution
  âœ“ Conflict detection and resolution

ğŸ’° Cost Estimate:
  ~1250 tokens used
  ~$0.0025 estimated cost
*/
